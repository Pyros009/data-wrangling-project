{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp, http, asyncio, requests, re, time, os, json, pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import steam_tags_f as stf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING THE TAGS AND MULTIPLAYER INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://api.steampowered.com/ISteamApps/GetAppList/v2/\"\n",
    "token = \"1AC3575ADB761319F3EF72D1FA362232\"\n",
    "params = {\"key\":token}\n",
    "\n",
    "scode, data = get_url(url, params=params, type = \"api\")\n",
    "display(scode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dict = {app['name']: app['appid'] for app in data['applist']['apps']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000 = pd.read_csv('TOP 1000 Games cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000[\"APP ID\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top1000_2 = stf.add_appid(top1000,app_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top1000.to_csv('TOP 1000 Games cleaned AppId.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually entered some app-ids that were not fetched\n",
    "appid_fix = pd.read_csv('top_1000_games_cleaned_appid_fix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appid_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = pd.read_csv(r\"top_1000_games_cleaned_appid_fix.csv\")\n",
    "txt = txt.rename({\"Game Title\":\"title\", \"Steam App ID\":\"id\"}, axis=1)\n",
    "appid_list = list(txt[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "appid = 2923300\n",
    "\n",
    "# Step 1: Make a request to the Steam API\n",
    "response = requests.get(f\"http://store.steampowered.com/api/appdetails?appids={appid}\")\n",
    "\n",
    "# Step 2: Parse the response\n",
    "game = response.json()\n",
    "\n",
    "#Step 3: Pretty-print the JSON response for better readability\n",
    "print(json.dumps(game, indent=4))  # Format with indentation of 4 spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = game[\"2923300\"][\"data\"][\"genres\"]\n",
    "descriptions = [genre[\"description\"] for genre in genres]\n",
    "print (descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stf.check_multiplayer_single(\"1599340\")\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag_dict = stf.get_tags(appid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"tag_dict.pkl\", \"rb\") as tag_dict_file:\n",
    "    tag_dict = pickle.load(tag_dict_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "appid_fix[\"tags\"] = 0\n",
    "\n",
    "#steam_df_tags = stf.add_tags(appid_fix,tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"steam_df_tags.pkl\", \"rb\") as steam_df_tags_file:\n",
    "    steam_df_tags = pickle.load(steam_df_tags_file)\n",
    "\n",
    "steam_df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steam_df_tags.to_csv('steam_appid_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"1AC3575ADB761319F3EF72D1FA362232\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp_dict = stf.check_multiplayer(appid_list, token, delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"mp_dict.pkl\", \"rb\") as mp_dict_file:\n",
    "    mp_dict = pickle.load(mp_dict_file)\n",
    "\n",
    "mp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_df_tags_mp = stf.add_mp(steam_df_tags, mp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_df_tags_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_df_tags_mp.to_csv('steam_appid_tags_mp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_mp_dict = steam_df_tags_mp.set_index(\"Steam App ID\")[\"tags\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_mp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open (\"tags_mp_dict.pkl\", \"wb\") as tags_mp_dict_file:\n",
    "    #pickle.dump(tags_mp_dict, tags_mp_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_name_dict = steam_df_tags_mp.set_index(\"Steam App ID\")[\"Game Title\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_name_dict[226320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open (\"tags_name_dict.pkl\", \"wb\") as tags_name_dict_file:\n",
    "   # pickle.dump(tags_name_dict, tags_name_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3_extracted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags_mp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for transposing new_df = out3_extracted.T.copy()\n",
    "\n",
    "new_df = out3_extracted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame(tags_mp_dict, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add row [0]\n",
    "for col in new_df.columns:\n",
    "    if col in tags_mp_dict.keys()\n",
    "        row [0][column] = tags_mp_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new row of zeroes with the same number of columns as df\n",
    "zero_row = pd.DataFrame([[0] * len(new_df.columns)], columns=new_df.columns)\n",
    "\n",
    "# Concatenate the new zero row at index 0\n",
    "new_df_0 = pd.concat([zero_row, new_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_mp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_mp_dict_str = {str(key):value for key, value in tags_mp_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_mp_dict_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = add_tags_df(new_df_0, tags_mp_dict_str)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def add_tags_df (df, dict):\n",
    "    df2 = df.copy()\n",
    "    for col in df2.columns:\n",
    "        int_key = int(col)\n",
    "        if int_key in map (int, dict.keys()):\n",
    "            df2.at[0, col] = dict[str(col)]\n",
    "    return df2\n",
    "\"\"\"        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for col in df2.columns:\n",
    "        # Convert the integer key to string for comparison\n",
    "        str_key = str(col)\n",
    "        if str_key in map(str, tags_mp_dict.keys()):  # Check if the string version of the key exists in dictionary\n",
    "            df2.at[0, col] = tags_mp_dict[int(col)]  # Use .at to set value by label\n",
    "\n",
    "    return df2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url, headers=None, params=None, type=\"ws\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        url (str): pass on url\n",
    "        type (str): define \"ws\" (webscrapping) or \"api\" (for API/json output), default is ws\n",
    "        headers (str, optional): Defaults to None.\n",
    "        params (dict, optional): Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        stat , response: outputs stat code and response content, either soup or json type.\n",
    "    \"\"\"\n",
    "    response = requests.get(url,headers=headers, params=params)\n",
    "    stat = response.status_code\n",
    "    if type.lower() == \"ws\":\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    elif type.lower() == \"api\":\n",
    "        soup = response.json()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return stat, soup\n",
    "\n",
    "def fetch_dict(soup, gameid):\n",
    "    k_value = 0\n",
    "    players = soup.find(\"tbody\")\n",
    "    play = re.split(r\"[\\n\\t]+\",players.get_text().strip())\n",
    "    player_game = {} \n",
    "\n",
    "    for i in range(0, len(play), 5):\n",
    "        # Date\n",
    "        date = play[i]\n",
    "        # Peak players\n",
    "        peak = play[i+1]  \n",
    "        # Average players\n",
    "        average = play[i +4]\n",
    "        player_game[k_value]={\"Date\": date,\n",
    "                            \"Peak Players\":peak,\n",
    "                            \"Avg Players\":average,\n",
    "        }\n",
    "        \n",
    "        k_value += 1\n",
    "        \n",
    "    return player_game\n",
    "\n",
    "def overall_fetch(list_id):\n",
    "    error_list =[]\n",
    "    game_id_dict = {}\n",
    "    for gameid in list_id:\n",
    "        gameid = str(gameid)\n",
    "        url = f'https://steamcharts.com/app/{gameid}'\n",
    "        headers= {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'}\n",
    "        try:\n",
    "            stat, soup = get_url(url, headers=headers, params=gameid)\n",
    "            if stat == 200:\n",
    "                print(f\"Webcode status is : {stat} for {gameid} id. \")\n",
    "                player_game = fetch_dict(soup, gameid)\n",
    "                game_id_dict[gameid] = player_game.copy()\n",
    "            else:\n",
    "                error_list.append((gameid, stat))\n",
    "                print(f\"Appid: {gameid} reported an error {stat}, skipping it for now\")    \n",
    "        except Exception as e:  # Catch specific exceptions\n",
    "            error_list.append((gameid, stat))\n",
    "            print(f\"App ID: {gameid} reported an error: {str(e)}, skipping it for now.\")\n",
    "            \n",
    "    \n",
    "    return game_id_dict, error_list\n",
    "\n",
    "def add_tags_df (df, dict):\n",
    "    df2 = df.copy()\n",
    "    for col in df2.columns:\n",
    "        if col in dict.keys():\n",
    "            df2.at[0, col] = dict[col]\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the games id list\n",
    "txt = pd.read_csv(r\"C:\\\\Users\\\\Utilizador\\\\Desktop\\\\IRONHACK\\\\Project 3\\\\Project-3\\\\top1k.csv\")\n",
    "txt = txt.rename({\"Game Title\":\"title\", \"Steam App ID\":\"id\"}, axis=1)\n",
    "list_id = list(txt[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main program, output\n",
    "\n",
    "game_id_dict, error_list = overall_fetch(list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves our main source of information into a feather\n",
    "output = pd.DataFrame.from_dict(game_id_dict)\n",
    "output.to_feather(\"output.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves our error results into an error csv\n",
    "err_table = pd.DataFrame(error_list)\n",
    "err_table.to_csv(\"error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bridges the webscrapping/API part with the cleaning and processing parts\n",
    "\n",
    "# imports our feather database & gives us an idea of the shape/NaN's present\n",
    "output = pd.read_feather(\"C:\\\\Users\\\\Utilizador\\\\Desktop\\\\IRONHACK\\\\Project 3\\\\Project-3\\\\output.feather\")\n",
    "output.isna().sum()\n",
    "display(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans database of most recent games (so from Aug 2019 -> Present)\n",
    "out2 = output.copy() \n",
    "filtered = out2.isna().sum(axis=0) > 85 ## 85 = Aug 2019\n",
    "filter = filtered[filtered]\n",
    "\n",
    "mask = list(filter.index)\n",
    "for code in mask:\n",
    "    out2.drop(code, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts \"Date\" into DataFrame index\n",
    "out3=out2.copy()\n",
    "out2_extracted = out2.applymap(lambda x: x[\"Date\"] if isinstance(x, dict) else x) \n",
    "\n",
    "out3[\"Date\"] = out2_extracted[\"730\"]\n",
    "\n",
    "# Define a new row of zeroes with the same number of columns as df\n",
    "zero_row = pd.DataFrame([[0] * len(out3.columns)], columns=out3.columns)\n",
    "\n",
    "# Concatenate the new zero row at index 0\n",
    "new_df_0 = pd.concat([zero_row, out3]).reset_index(drop=True)\n",
    "tags_mp_dict_str = {str(key):value for key, value in tags_mp_dict.items()}\n",
    "\n",
    "# Adds tag into row 0, also gives the column a name\n",
    "out3_new = add_tags_df(new_df_0, tags_mp_dict_str)\n",
    "out3_new[\"Date\"][0] = \"Tags\"\n",
    "\n",
    "# Set's date as index\n",
    "out3_new.set_index('Date', inplace=True)\n",
    "\n",
    "# filters the table for the data we want\n",
    "out3_extracted = out3_new.applymap(lambda x: x[\"Avg Players\"] if isinstance(x, dict) else x)\n",
    "\n",
    "display(out3_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts columns into game's name\n",
    "out4 = out3_extracted.copy()\n",
    "# creates the id list\n",
    "txt2 = txt.rename({\"Game Title\":\"title\", \"Steam App ID\":\"id\"}, axis=1)\n",
    "txt2 = txt2[[\"id\",\"title\"]]\n",
    "txt2.set_index(\"id\", inplace=True)\n",
    "\n",
    "# Create a mapping from ids to titles\n",
    "title_mapping = {str(k): v for k, v in txt2[\"title\"].to_dict().items()}\n",
    "\n",
    "# Rename the columns in out4 using the mapping\n",
    "out4.columns = [title_mapping.get(str(col), col) for col in out4.columns]\n",
    "\n",
    "# Creates our main dataframe visualization \n",
    "visual = \"Peak Players\"\n",
    "out4 = out4.applymap(lambda x: x[visual] if isinstance(x, dict) else x)\n",
    "out4[1:] = round(out4[1:].fillna(0).astype(float),0).astype(int)\n",
    "out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More cleaning while looking at data. Disregarding outliers etc..\n",
    "out5 = out4.copy()\n",
    "\n",
    "## Drops useless games that make weird spikes\n",
    "out5.drop(\"POSTAL\", axis=1, inplace=True)\n",
    "\n",
    "# Creates a new column (Total) and concats into the existing dataframe\n",
    "total_column = out5.sum(axis = 1)\n",
    "out5 = pd.concat([out5, total_column.rename(\"Total\")], axis=1)\n",
    "\n",
    "out5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization 1 (average gains) - Assuming 'Total' is the column you want to apply the formula to\n",
    "#out5['Value'][1:] = (out5['Total'][1:] - out5['Total'][1:].shift(-1)) / out5['Total'][1:]\n",
    "\n",
    "out5[\"Value\"] = out5[\"Total\"]\n",
    "out5[\"Value\"] = 0\n",
    "out5['Value'][1:] = (out5['Total'][1:] - out5['Total'][1:].shift(-1)) / out5['Total'][1:]\n",
    "\n",
    "display(out5)\n",
    "#display(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new copy\n",
    "out6 = out5.copy()\n",
    "\n",
    "# further normalizations - Z score normalization\n",
    "def z_norm(column):\n",
    "    mean = column.mean()\n",
    "    std_dev = column.std()\n",
    "    return (column - mean) / std_dev\n",
    "\n",
    "out6['Z'] = out6['Value']\n",
    "out6['Z'] = 0\n",
    "out6['Z'][1:] = z_norm(out6['Total'][1:])\n",
    "\n",
    "out6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "out7 = out6.copy()\n",
    "\n",
    "print(out7.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filter_tags = out7[out7.index.str.contains('Multiplayer', case=False, na=False)]\n",
    "print(filter_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Data Visualization \n",
    "\n",
    "# Set theme and palette\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Create a line plot for Total values over Date\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size\n",
    "sns.lineplot(data=out7[1:], x=out7.index[1:], y='Z', marker='o', linestyle='--', linewidth=2)\n",
    "\n",
    "#### Add a vertical line on a specific date\n",
    "\n",
    "# Covid related lines\n",
    "plt.axvline(x=\"November 2019\", color='orange', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=\"January 2020\", color='red', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=\"June 2020\", color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.text(x=\"November 2019\", y=-2,  s='Nov19: China warns about Covid', color='orange', fontsize=10, ha='right', rotation=90)\n",
    "plt.text(x=\"January 2020\", y=-2, s='Jan20: WHO acknoledges Covid', color='red', fontsize=10, ha='left', rotation=90)\n",
    "plt.text(x=\"June 2020\", y=-2, s='Jun20: end of first big lockdown period', color='green', fontsize=10, ha='right', rotation=90)\n",
    "\n",
    "# Game related lines\n",
    "plt.axvline(x=\"December 2017\", color='cyan', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=\"December 2020\", color='cyan', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=\"September 2021\", color='cyan', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=\"February 2021\", color='cyan', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=\"March 2019\", color='cyan', linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "plt.text(x=\"December 2017\", y=-2, s=\"PUBG goes live\", color='cyan', fontsize=10, ha='right', rotation=90)\n",
    "plt.text(x=\"December 2020\", y=-2, s=\"Cyberpunk goes live\", color='cyan', fontsize=10, ha='right', rotation=90)\n",
    "plt.text(x=\"September 2021\", y=-2, s=\"New World goes live\", color='cyan', fontsize=10, ha='right', rotation=90)\n",
    "plt.text(x=\"February 2021\", y=-2, s=\"Valheim goes live\", color='cyan', fontsize=10, ha='right', rotation=90)\n",
    "plt.text(x=\"March 2019\", y=-2, s=\"Sekiro goes live\", color='cyan', fontsize=10, ha='right', rotation=90)\n",
    "\n",
    "### Graphic formatting\n",
    "\n",
    "# Format the date on the x-axis\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "\n",
    "#Limit x-axis onto a specific interval \n",
    "plt.xlim('August 2022', 'August 2018')  # Specify the limits as strings\n",
    "plt.gca().invert_xaxis() # inverts the x-axis (more suited for dates as it grows from left to right)\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Z-values Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Z-Value')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
